{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/manmeet3/Deep_Learning2/blob/master/Asg4/multi-task_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code for a multi-objective movie recommendation model. An example use case for such a model can be seen at http://movielens.org. We follow the multitask example from tensorflow.org\n",
    "\n",
    "There are two critical parts of multi-task recommenders:\n",
    "1. They optimize for two or more objectives, and so have two or more losses\n",
    "2. They share variables between the tasks, allowing for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow recommenders is an extension library of core tensorflow.\n",
    "Ref: https://www.tensorflow.org/resources/libraries-extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the movielens 100k ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The handle \"movie_lens\" for the MovieLens dataset is deprecated. Prefer using \"movielens\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset movie_lens/100k-ratings/0.1.0 (download: 4.70 MiB, generated: 32.41 MiB, total: 37.10 MiB) to /root/tensorflow_datasets/movie_lens/100k-ratings/0.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ce9b9a83c349f5a2bfedb910516a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd2d28bb45c4071940792de96818b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d5a43331064a33a345dd10e28cae1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /root/tensorflow_datasets/movie_lens/100k-ratings/0.1.0.incomplete8GYDJL/movie_lens-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a1635eeef4469d8327b5e472ee3eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movie_lens downloaded and prepared to /root/tensorflow_datasets/movie_lens/100k-ratings/0.1.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The handle \"movie_lens\" for the MovieLens dataset is deprecated. Prefer using \"movielens\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset movie_lens/100k-movies/0.1.0 (download: 4.70 MiB, generated: 150.35 KiB, total: 4.84 MiB) to /root/tensorflow_datasets/movie_lens/100k-movies/0.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3430a48321a145bca31dde8866b35a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac50f5abcfe6460da259df94582c3d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd55748c7b34da19af4f5cf4a300631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /root/tensorflow_datasets/movie_lens/100k-movies/0.1.0.incomplete8QDIG5/movie_lens-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b018596f19be47519b9bbca917c2f347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1682.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movie_lens downloaded and prepared to /root/tensorflow_datasets/movie_lens/100k-movies/0.1.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load('movie_lens/100k-ratings', split=\"train\")\n",
    "movies = tfds.load('movie_lens/100k-movies', split=\"train\")\n",
    "\n",
    "# Select basic features\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "})\n",
    "\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the data and split between train and test\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task model\n",
    "The two critical tasks for multi-task recommenders are:\n",
    "1. Optimization of two or more objectvies -- they must have 2 or more loss functions\n",
    "2. They share variables between tasks, allowing for transfer learning\n",
    "\n",
    "In this colab, we define a model which has two tasks:\n",
    "1. Predict ratings per user\n",
    "2. Predict movie watches per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "    def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "        # Taking loss weights in constructor allows multiple model objects with different loss weights\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dimension=32\n",
    "        \n",
    "        # User and movie models\n",
    "        self.user_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, self.embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_movie_titles) + 1, self.embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "        # A small model to take user and movie embeddings as input and predict ratings\n",
    "        # This can be made more complicated as long as a scaler is output for prediction\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "        \n",
    "        # 2 Model Tasks\n",
    "        # First is the rating task\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        # Retrieval task for the movies a user may be interested in\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "            \n",
    "        # The loss weights\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "        \n",
    "    def call(self, features: Dict[Text, tf.Tensor], training=False):\n",
    "        # Pick out user and movie features and convert them to embeddings\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        return(\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            # apply multi-layers rating model to concat of user and movie embeddings\n",
    "            self.rating_model(tf.concat([user_embeddings, movie_embeddings], axis=1)),\n",
    "        )\n",
    "        \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # We compute the loss for each task\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=features[\"user_rating\"],\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        \n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "        \n",
    "        # Combine using loss weights\n",
    "        return (self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating-specialized model\n",
    "Depending on the weights provided at initialization time, the MTL model will weight the predictions in favor of that. Here we start with complete emphasis on ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=0.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 2.0838 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0027 - factorized_top_k/top_10_categorical_accuracy: 0.0058 - factorized_top_k/top_50_categorical_accuracy: 0.0292 - factorized_top_k/top_100_categorical_accuracy: 0.0595 - loss: 4.0124 - regularization_loss: 0.0000e+00 - total_loss: 4.0124\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 4s 397ms/step - root_mean_squared_error: 1.1518 - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0026 - factorized_top_k/top_10_categorical_accuracy: 0.0058 - factorized_top_k/top_50_categorical_accuracy: 0.0293 - factorized_top_k/top_100_categorical_accuracy: 0.0595 - loss: 1.3178 - regularization_loss: 0.0000e+00 - total_loss: 1.3178\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 4s 392ms/step - root_mean_squared_error: 1.1159 - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0025 - factorized_top_k/top_10_categorical_accuracy: 0.0058 - factorized_top_k/top_50_categorical_accuracy: 0.0297 - factorized_top_k/top_100_categorical_accuracy: 0.0604 - loss: 1.2415 - regularization_loss: 0.0000e+00 - total_loss: 1.2415\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 4s 394ms/step - root_mean_squared_error: 1.1024 - factorized_top_k/top_1_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0026 - factorized_top_k/top_10_categorical_accuracy: 0.0058 - factorized_top_k/top_50_categorical_accuracy: 0.0306 - factorized_top_k/top_100_categorical_accuracy: 0.0606 - loss: 1.2115 - regularization_loss: 0.0000e+00 - total_loss: 1.2115\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 4s 401ms/step - root_mean_squared_error: 1.0857 - factorized_top_k/top_1_categorical_accuracy: 1.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0061 - factorized_top_k/top_50_categorical_accuracy: 0.0318 - factorized_top_k/top_100_categorical_accuracy: 0.0616 - loss: 1.1747 - regularization_loss: 0.0000e+00 - total_loss: 1.1747\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 4s 396ms/step - root_mean_squared_error: 1.0646 - factorized_top_k/top_1_categorical_accuracy: 2.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0066 - factorized_top_k/top_50_categorical_accuracy: 0.0328 - factorized_top_k/top_100_categorical_accuracy: 0.0634 - loss: 1.1296 - regularization_loss: 0.0000e+00 - total_loss: 1.1296\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 4s 407ms/step - root_mean_squared_error: 1.0541 - factorized_top_k/top_1_categorical_accuracy: 2.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0033 - factorized_top_k/top_10_categorical_accuracy: 0.0072 - factorized_top_k/top_50_categorical_accuracy: 0.0339 - factorized_top_k/top_100_categorical_accuracy: 0.0649 - loss: 1.1118 - regularization_loss: 0.0000e+00 - total_loss: 1.1118\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 4s 409ms/step - root_mean_squared_error: 1.0663 - factorized_top_k/top_1_categorical_accuracy: 4.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0037 - factorized_top_k/top_10_categorical_accuracy: 0.0078 - factorized_top_k/top_50_categorical_accuracy: 0.0349 - factorized_top_k/top_100_categorical_accuracy: 0.0664 - loss: 1.1298 - regularization_loss: 0.0000e+00 - total_loss: 1.1298\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 4s 396ms/step - root_mean_squared_error: 1.0181 - factorized_top_k/top_1_categorical_accuracy: 3.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0038 - factorized_top_k/top_10_categorical_accuracy: 0.0080 - factorized_top_k/top_50_categorical_accuracy: 0.0356 - factorized_top_k/top_100_categorical_accuracy: 0.0675 - loss: 1.0315 - regularization_loss: 0.0000e+00 - total_loss: 1.0315\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 0.9943 - factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0036 - factorized_top_k/top_10_categorical_accuracy: 0.0080 - factorized_top_k/top_50_categorical_accuracy: 0.0360 - factorized_top_k/top_100_categorical_accuracy: 0.0687 - loss: 0.9861 - regularization_loss: 0.0000e+00 - total_loss: 0.9861\n",
      "5/5 [==============================] - 1s 204ms/step - root_mean_squared_error: 0.9976 - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0041 - factorized_top_k/top_10_categorical_accuracy: 0.0078 - factorized_top_k/top_50_categorical_accuracy: 0.0357 - factorized_top_k/top_100_categorical_accuracy: 0.0662 - loss: 0.9928 - regularization_loss: 0.0000e+00 - total_loss: 0.9928\n",
      "Retrieval top-100 accuracy: 0.066.\n",
      "Ranking RMSE: 0.998.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=10)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-specialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=0.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 391ms/step - root_mean_squared_error: 3.6985 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0040 - factorized_top_k/top_50_categorical_accuracy: 0.0440 - factorized_top_k/top_100_categorical_accuracy: 0.1054 - loss: 69896.6271 - regularization_loss: 0.0000e+00 - total_loss: 69896.6271\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 4s 385ms/step - root_mean_squared_error: 3.6828 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0111 - factorized_top_k/top_10_categorical_accuracy: 0.0256 - factorized_top_k/top_50_categorical_accuracy: 0.1392 - factorized_top_k/top_100_categorical_accuracy: 0.2626 - loss: 67519.7464 - regularization_loss: 0.0000e+00 - total_loss: 67519.7464\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 4s 400ms/step - root_mean_squared_error: 3.6746 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0186 - factorized_top_k/top_10_categorical_accuracy: 0.0399 - factorized_top_k/top_50_categorical_accuracy: 0.1761 - factorized_top_k/top_100_categorical_accuracy: 0.3043 - loss: 66300.5582 - regularization_loss: 0.0000e+00 - total_loss: 66300.5582\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 4s 386ms/step - root_mean_squared_error: 3.6720 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0218 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - factorized_top_k/top_50_categorical_accuracy: 0.1954 - factorized_top_k/top_100_categorical_accuracy: 0.3279 - loss: 65615.3551 - regularization_loss: 0.0000e+00 - total_loss: 65615.3551\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 4s 392ms/step - root_mean_squared_error: 3.6715 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0238 - factorized_top_k/top_10_categorical_accuracy: 0.0512 - factorized_top_k/top_50_categorical_accuracy: 0.2096 - factorized_top_k/top_100_categorical_accuracy: 0.3435 - loss: 65120.6641 - regularization_loss: 0.0000e+00 - total_loss: 65120.6641\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 4s 397ms/step - root_mean_squared_error: 3.6720 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0262 - factorized_top_k/top_10_categorical_accuracy: 0.0549 - factorized_top_k/top_50_categorical_accuracy: 0.2205 - factorized_top_k/top_100_categorical_accuracy: 0.3563 - loss: 64733.1051 - regularization_loss: 0.0000e+00 - total_loss: 64733.1051\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 4s 391ms/step - root_mean_squared_error: 3.6731 - factorized_top_k/top_1_categorical_accuracy: 8.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0271 - factorized_top_k/top_10_categorical_accuracy: 0.0580 - factorized_top_k/top_50_categorical_accuracy: 0.2290 - factorized_top_k/top_100_categorical_accuracy: 0.3658 - loss: 64420.1804 - regularization_loss: 0.0000e+00 - total_loss: 64420.1804\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 4s 393ms/step - root_mean_squared_error: 3.6743 - factorized_top_k/top_1_categorical_accuracy: 7.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0289 - factorized_top_k/top_10_categorical_accuracy: 0.0602 - factorized_top_k/top_50_categorical_accuracy: 0.2354 - factorized_top_k/top_100_categorical_accuracy: 0.3736 - loss: 64163.7685 - regularization_loss: 0.0000e+00 - total_loss: 64163.7685\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 4s 395ms/step - root_mean_squared_error: 3.6756 - factorized_top_k/top_1_categorical_accuracy: 9.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0300 - factorized_top_k/top_10_categorical_accuracy: 0.0623 - factorized_top_k/top_50_categorical_accuracy: 0.2401 - factorized_top_k/top_100_categorical_accuracy: 0.3803 - loss: 63951.2621 - regularization_loss: 0.0000e+00 - total_loss: 63951.2621\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 4s 398ms/step - root_mean_squared_error: 3.6768 - factorized_top_k/top_1_categorical_accuracy: 7.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0309 - factorized_top_k/top_10_categorical_accuracy: 0.0631 - factorized_top_k/top_50_categorical_accuracy: 0.2442 - factorized_top_k/top_100_categorical_accuracy: 0.3847 - loss: 63773.1278 - regularization_loss: 0.0000e+00 - total_loss: 63773.1278\n",
      "5/5 [==============================] - 1s 194ms/step - root_mean_squared_error: 3.6790 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0033 - factorized_top_k/top_10_categorical_accuracy: 0.0094 - factorized_top_k/top_50_categorical_accuracy: 0.0878 - factorized_top_k/top_100_categorical_accuracy: 0.1874 - loss: 31662.5814 - regularization_loss: 0.0000e+00 - total_loss: 31662.5814\n",
      "Retrieval top-100 accuracy: 0.187.\n",
      "Ranking RMSE: 3.679.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=10)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 4s 397ms/step - root_mean_squared_error: 0.9865 - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0036 - factorized_top_k/top_10_categorical_accuracy: 0.0080 - factorized_top_k/top_50_categorical_accuracy: 0.0359 - factorized_top_k/top_100_categorical_accuracy: 0.0690 - loss: 0.9708 - regularization_loss: 0.0000e+00 - total_loss: 0.9708\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 4s 392ms/step - root_mean_squared_error: 0.9771 - factorized_top_k/top_1_categorical_accuracy: 3.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0035 - factorized_top_k/top_10_categorical_accuracy: 0.0077 - factorized_top_k/top_50_categorical_accuracy: 0.0357 - factorized_top_k/top_100_categorical_accuracy: 0.0687 - loss: 0.9517 - regularization_loss: 0.0000e+00 - total_loss: 0.9517\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 0.9648 - factorized_top_k/top_1_categorical_accuracy: 4.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0034 - factorized_top_k/top_10_categorical_accuracy: 0.0077 - factorized_top_k/top_50_categorical_accuracy: 0.0356 - factorized_top_k/top_100_categorical_accuracy: 0.0686 - loss: 0.9282 - regularization_loss: 0.0000e+00 - total_loss: 0.9282\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 4s 390ms/step - root_mean_squared_error: 0.9562 - factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0034 - factorized_top_k/top_10_categorical_accuracy: 0.0075 - factorized_top_k/top_50_categorical_accuracy: 0.0354 - factorized_top_k/top_100_categorical_accuracy: 0.0684 - loss: 0.9119 - regularization_loss: 0.0000e+00 - total_loss: 0.9119\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 4s 398ms/step - root_mean_squared_error: 0.9510 - factorized_top_k/top_1_categorical_accuracy: 2.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0033 - factorized_top_k/top_10_categorical_accuracy: 0.0072 - factorized_top_k/top_50_categorical_accuracy: 0.0350 - factorized_top_k/top_100_categorical_accuracy: 0.0681 - loss: 0.9023 - regularization_loss: 0.0000e+00 - total_loss: 0.9023\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 4s 393ms/step - root_mean_squared_error: 0.9477 - factorized_top_k/top_1_categorical_accuracy: 2.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0032 - factorized_top_k/top_10_categorical_accuracy: 0.0070 - factorized_top_k/top_50_categorical_accuracy: 0.0347 - factorized_top_k/top_100_categorical_accuracy: 0.0677 - loss: 0.8961 - regularization_loss: 0.0000e+00 - total_loss: 0.8961\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 4s 391ms/step - root_mean_squared_error: 0.9446 - factorized_top_k/top_1_categorical_accuracy: 3.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0033 - factorized_top_k/top_10_categorical_accuracy: 0.0069 - factorized_top_k/top_50_categorical_accuracy: 0.0345 - factorized_top_k/top_100_categorical_accuracy: 0.0673 - loss: 0.8902 - regularization_loss: 0.0000e+00 - total_loss: 0.8902\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 4s 399ms/step - root_mean_squared_error: 0.9411 - factorized_top_k/top_1_categorical_accuracy: 3.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0032 - factorized_top_k/top_10_categorical_accuracy: 0.0068 - factorized_top_k/top_50_categorical_accuracy: 0.0343 - factorized_top_k/top_100_categorical_accuracy: 0.0673 - loss: 0.8834 - regularization_loss: 0.0000e+00 - total_loss: 0.8834\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 4s 395ms/step - root_mean_squared_error: 0.9376 - factorized_top_k/top_1_categorical_accuracy: 3.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0032 - factorized_top_k/top_10_categorical_accuracy: 0.0066 - factorized_top_k/top_50_categorical_accuracy: 0.0341 - factorized_top_k/top_100_categorical_accuracy: 0.0671 - loss: 0.8770 - regularization_loss: 0.0000e+00 - total_loss: 0.8770\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 4s 396ms/step - root_mean_squared_error: 0.9349 - factorized_top_k/top_1_categorical_accuracy: 3.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0031 - factorized_top_k/top_10_categorical_accuracy: 0.0065 - factorized_top_k/top_50_categorical_accuracy: 0.0340 - factorized_top_k/top_100_categorical_accuracy: 0.0666 - loss: 0.8719 - regularization_loss: 0.0000e+00 - total_loss: 0.8719\n",
      "5/5 [==============================] - 1s 191ms/step - root_mean_squared_error: 0.9490 - factorized_top_k/top_1_categorical_accuracy: 6.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0033 - factorized_top_k/top_10_categorical_accuracy: 0.0074 - factorized_top_k/top_50_categorical_accuracy: 0.0332 - factorized_top_k/top_100_categorical_accuracy: 0.0634 - loss: 0.9001 - regularization_loss: 0.0000e+00 - total_loss: 0.9001\n",
      "Retrieval top-100 accuracy: 0.063.\n",
      "Ranking RMSE: 0.949.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=10)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model is a combination of the user-rating prediction and movie recommendation retrieval. In doing so, it is able to retrive movies based on user recommendation\n",
    "\n",
    "The overall model logic in the notebook is unoptimized for the single or joint models. A more elaborative NN can be implemented in the self.rating_model of the notebook. The rating model takes the embeddings of user and movie models and predicts what a user is likely to rate a recommended movie, were they to watch it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.tensorflow.org/recommenders/examples/multitask"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPenNO0IWbX5nC+Hm8vVD7E",
   "include_colab_link": true,
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
